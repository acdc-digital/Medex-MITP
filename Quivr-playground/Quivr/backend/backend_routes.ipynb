{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. FastAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "\n",
    "origins = [\n",
    "    \"http://localhost\",\n",
    "    \"http://localhost:3000\",\n",
    "    \"http://localhost:3001\",\n",
    "    \"https://quivr.app\",\n",
    "    \"https://www.quivr.app\",\n",
    "    \"http://quivr.app\",\n",
    "    \"http://www.quivr.app\",\n",
    "    \"*\"\n",
    "]\n",
    "\n",
    "\n",
    "def add_cors_middleware(app):\n",
    "    app.add_middleware(\n",
    "        CORSMiddleware,\n",
    "        allow_origins=origins,\n",
    "        allow_credentials=True,\n",
    "        allow_methods=[\"*\"],\n",
    "        allow_headers=[\"*\"],\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from typing import Any, Optional\n",
    "from uuid import UUID\n",
    "\n",
    "from fastapi import UploadFile\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from logger import get_logger\n",
    "from pydantic import BaseModel\n",
    "from utils.file import compute_sha1_from_file\n",
    "\n",
    "from models.brains import Brain\n",
    "from models.settings import CommonsDep, common_dependencies\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "class File(BaseModel):\n",
    "    id: Optional[UUID] = None\n",
    "    file: Optional[UploadFile]\n",
    "    file_name: Optional[str] = \"\"\n",
    "    file_size: Optional[int] = \"\"  # pyright: ignore reportPrivateUsage=none\n",
    "    file_sha1: Optional[str] = \"\"\n",
    "    vectors_ids: Optional[int] = []  # pyright: ignore reportPrivateUsage=none\n",
    "    file_extension: Optional[str] = \"\"\n",
    "    content: Optional[Any] = None\n",
    "    chunk_size: int = 500\n",
    "    chunk_overlap: int = 0\n",
    "    documents: Optional[Any] = None\n",
    "    _commons: Optional[CommonsDep] = None\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        if self.file:\n",
    "            self.file_name = self.file.filename\n",
    "            self.file_size = (\n",
    "                self.file.file._file.tell()  # pyright: ignore reportPrivateUsage=none\n",
    "            )\n",
    "            self.file_extension = os.path.splitext(\n",
    "                self.file.filename  # pyright: ignore reportPrivateUsage=none\n",
    "            )[-1].lower()\n",
    "\n",
    "    async def compute_file_sha1(self):\n",
    "        with tempfile.NamedTemporaryFile(\n",
    "            delete=False,\n",
    "            suffix=self.file.filename,  # pyright: ignore reportPrivateUsage=none\n",
    "        ) as tmp_file:\n",
    "            await self.file.seek(0)  # pyright: ignore reportPrivateUsage=none\n",
    "            self.content = (\n",
    "                await self.file.read()  # pyright: ignore reportPrivateUsage=none\n",
    "            )\n",
    "            tmp_file.write(self.content)\n",
    "            tmp_file.flush()\n",
    "            self.file_sha1 = compute_sha1_from_file(tmp_file.name)\n",
    "\n",
    "        os.remove(tmp_file.name)\n",
    "\n",
    "    def compute_documents(self, loader_class):\n",
    "        logger.info(f\"Computing documents from file {self.file_name}\")\n",
    "\n",
    "        documents = []\n",
    "        with tempfile.NamedTemporaryFile(\n",
    "            delete=False,\n",
    "            suffix=self.file.filename,  # pyright: ignore reportPrivateUsage=none\n",
    "        ) as tmp_file:\n",
    "            tmp_file.write(self.content)  # pyright: ignore reportPrivateUsage=none\n",
    "            tmp_file.flush()\n",
    "            loader = loader_class(tmp_file.name)\n",
    "            documents = loader.load()\n",
    "\n",
    "            print(\"documents\", documents)\n",
    "\n",
    "        os.remove(tmp_file.name)\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "            chunk_size=self.chunk_size, chunk_overlap=self.chunk_overlap\n",
    "        )\n",
    "\n",
    "        self.documents = text_splitter.split_documents(documents)\n",
    "\n",
    "        print(self.documents)\n",
    "\n",
    "    def set_file_vectors_ids(self):\n",
    "        \"\"\"\n",
    "        Set the vectors_ids property with the ids of the vectors\n",
    "        that are associated with the file in the vectors table\n",
    "        \"\"\"\n",
    "\n",
    "        commons = common_dependencies()\n",
    "        response = (\n",
    "            commons[\"supabase\"]\n",
    "            .table(\"vectors\")\n",
    "            .select(\"id\")\n",
    "            .filter(\"metadata->>file_sha1\", \"eq\", self.file_sha1)\n",
    "            .execute()\n",
    "        )\n",
    "        self.vectors_ids = response.data\n",
    "        return\n",
    "\n",
    "    def file_already_exists(self):\n",
    "        \"\"\"\n",
    "        Check if file already exists in vectors table\n",
    "        \"\"\"\n",
    "        self.set_file_vectors_ids()\n",
    "\n",
    "        print(\"file_sha1\", self.file_sha1)\n",
    "        print(\"vectors_ids\", self.vectors_ids)\n",
    "        print(\n",
    "            \"len(vectors_ids)\",\n",
    "            len(self.vectors_ids),  # pyright: ignore reportPrivateUsage=none\n",
    "        )\n",
    "\n",
    "        # if the file does not exist in vectors then no need to go check in brains_vectors\n",
    "        if len(self.vectors_ids) == 0:  # pyright: ignore reportPrivateUsage=none\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def file_already_exists_in_brain(self, brain_id):\n",
    "        commons = common_dependencies()\n",
    "        self.set_file_vectors_ids()\n",
    "        # Check if file exists in that brain\n",
    "        response = (\n",
    "            commons[\"supabase\"]\n",
    "            .table(\"brains_vectors\")\n",
    "            .select(\"brain_id, vector_id\")\n",
    "            .filter(\"brain_id\", \"eq\", brain_id)\n",
    "            .filter(\"file_sha1\", \"eq\", self.file_sha1)\n",
    "            .execute()\n",
    "        )\n",
    "        print(\"response.data\", response.data)\n",
    "        if len(response.data) == 0:\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def file_is_empty(self):\n",
    "        return (\n",
    "            self.file.file._file.tell() < 1  # pyright: ignore reportPrivateUsage=none\n",
    "        )\n",
    "\n",
    "    def link_file_to_brain(self, brain: Brain):\n",
    "        self.set_file_vectors_ids()\n",
    "\n",
    "        for vector_id in self.vectors_ids:  # pyright: ignore reportPrivateUsage=none\n",
    "            brain.create_brain_vector(vector_id[\"id\"], self.file_sha1)\n",
    "        print(f\"Successfully linked file {self.file_sha1} to brain {brain.id}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. API-key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from secrets import token_hex\n",
    "from typing import List\n",
    "from uuid import uuid4\n",
    "\n",
    "from asyncpg.exceptions import UniqueViolationError\n",
    "from auth import AuthBearer, get_current_user\n",
    "from fastapi import APIRouter, Depends\n",
    "from logger import get_logger\n",
    "from models.settings import CommonsDep\n",
    "from models.users import User\n",
    "from pydantic import BaseModel\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "\n",
    "class ApiKeyInfo(BaseModel):\n",
    "    key_id: str\n",
    "    creation_time: str\n",
    "\n",
    "\n",
    "class ApiKey(BaseModel):\n",
    "    api_key: str\n",
    "    key_id: str\n",
    "\n",
    "\n",
    "api_key_router = APIRouter()\n",
    "\n",
    "\n",
    "@api_key_router.post(\n",
    "    \"/api-key\",\n",
    "    response_model=ApiKey,\n",
    "    dependencies=[Depends(AuthBearer())],\n",
    "    tags=[\"API Key\"],\n",
    ")\n",
    "async def create_api_key(\n",
    "    commons: CommonsDep, current_user: User = Depends(get_current_user)\n",
    "):\n",
    "    \"\"\"\n",
    "    Create new API key for the current user.\n",
    "\n",
    "    - `current_user`: The current authenticated user.\n",
    "    - Returns the newly created API key.\n",
    "\n",
    "    This endpoint generates a new API key for the current user. The API key is stored in the database and associated with\n",
    "    the user. It returns the newly created API key.\n",
    "    \"\"\"\n",
    "\n",
    "    new_key_id = uuid4()\n",
    "    new_api_key = token_hex(16)\n",
    "    api_key_inserted = False\n",
    "\n",
    "    while not api_key_inserted:\n",
    "        try:\n",
    "            # Attempt to insert new API key into database\n",
    "            commons[\"supabase\"].table(\"api_keys\").insert(\n",
    "                [\n",
    "                    {\n",
    "                        \"key_id\": str(new_key_id),\n",
    "                        \"user_id\": str(current_user.id),\n",
    "                        \"api_key\": str(new_api_key),\n",
    "                        \"creation_time\": datetime.utcnow().strftime(\n",
    "                            \"%Y-%m-%d %H:%M:%S\"\n",
    "                        ),\n",
    "                        \"is_active\": True,\n",
    "                    }\n",
    "                ]\n",
    "            ).execute()\n",
    "\n",
    "            api_key_inserted = True\n",
    "\n",
    "        except UniqueViolationError:\n",
    "            # Generate a new API key if the current one is already in use\n",
    "            new_api_key = token_hex(16)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error creating new API key: {e}\")\n",
    "            return {\"api_key\": \"Error creating new API key.\"}\n",
    "    logger.info(f\"Created new API key for user {current_user.email}.\")\n",
    "\n",
    "    return {\"api_key\": new_api_key, \"key_id\": str(new_key_id)}\n",
    "\n",
    "\n",
    "@api_key_router.delete(\n",
    "    \"/api-key/{key_id}\", dependencies=[Depends(AuthBearer())], tags=[\"API Key\"]\n",
    ")\n",
    "async def delete_api_key(\n",
    "    key_id: str, commons: CommonsDep, current_user: User = Depends(get_current_user)\n",
    "):\n",
    "    \"\"\"\n",
    "    Delete (deactivate) an API key for the current user.\n",
    "\n",
    "    - `key_id`: The ID of the API key to delete.\n",
    "\n",
    "    This endpoint deactivates and deletes the specified API key associated with the current user. The API key is marked\n",
    "    as inactive in the database.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    commons[\"supabase\"].table(\"api_keys\").update(\n",
    "        {\n",
    "            \"is_active\": False,\n",
    "            \"deleted_time\": datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        }\n",
    "    ).match({\"key_id\": key_id, \"user_id\": current_user.id}).execute()\n",
    "\n",
    "    return {\"message\": \"API key deleted.\"}\n",
    "\n",
    "\n",
    "@api_key_router.get(\n",
    "    \"/api-keys\",\n",
    "    response_model=List[ApiKeyInfo],\n",
    "    dependencies=[Depends(AuthBearer())],\n",
    "    tags=[\"API Key\"],\n",
    ")\n",
    "async def get_api_keys(\n",
    "    commons: CommonsDep, current_user: User = Depends(get_current_user)\n",
    "):\n",
    "    \"\"\"\n",
    "    Get all active API keys for the current user.\n",
    "\n",
    "    - `current_user`: The current authenticated user.\n",
    "    - Returns a list of active API keys with their IDs and creation times.\n",
    "\n",
    "    This endpoint retrieves all the active API keys associated with the current user. It returns a list of API key objects\n",
    "    containing the key ID and creation time for each API key.\n",
    "    \"\"\"\n",
    "\n",
    "    response = (\n",
    "        commons[\"supabase\"]\n",
    "        .table(\"api_keys\")\n",
    "        .select(\"key_id, creation_time\")\n",
    "        .filter(\"user_id\", \"eq\", current_user.id)\n",
    "        .filter(\"is_active\", \"eq\", True)\n",
    "        .execute()\n",
    "    )\n",
    "    return response.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from uuid import UUID\n",
    "\n",
    "from auth import AuthBearer, get_current_user\n",
    "from fastapi import APIRouter, Depends\n",
    "from logger import get_logger\n",
    "from models.brains import Brain, get_default_user_brain\n",
    "from models.settings import common_dependencies\n",
    "from models.users import User\n",
    "from pydantic import BaseModel\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "brain_router = APIRouter()\n",
    "\n",
    "\n",
    "class BrainToUpdate(BaseModel):\n",
    "    brain_id: UUID\n",
    "    name: Optional[str] = \"New Brain\"\n",
    "    status: Optional[str] = \"public\"\n",
    "    model: Optional[str] = \"gpt-3.5-turbo-0613\"\n",
    "    temperature: Optional[float] = 0.0\n",
    "    max_tokens: Optional[int] = 256\n",
    "    file_sha1: Optional[str] = \"\"\n",
    "\n",
    "\n",
    "# get all brains\n",
    "@brain_router.get(\"/brains/\", dependencies=[Depends(AuthBearer())], tags=[\"Brain\"])\n",
    "async def brain_endpoint(current_user: User = Depends(get_current_user)):\n",
    "    \"\"\"\n",
    "    Retrieve all brains for the current user.\n",
    "\n",
    "    - `current_user`: The current authenticated user.\n",
    "    - Returns a list of all brains registered for the user.\n",
    "\n",
    "    This endpoint retrieves all the brains associated with the current authenticated user. It returns a list of brains objects\n",
    "    containing the brain ID and brain name for each brain.\n",
    "    \"\"\"\n",
    "    brain = Brain()\n",
    "    brains = brain.get_user_brains(current_user.id)\n",
    "    return {\"brains\": brains}\n",
    "\n",
    "\n",
    "@brain_router.get(\n",
    "    \"/brains/default/\", dependencies=[Depends(AuthBearer())], tags=[\"Brain\"]\n",
    ")\n",
    "async def get_default_brain_endpoint(current_user: User = Depends(get_current_user)):\n",
    "    \"\"\"\n",
    "    Retrieve the default brain for the current user. If the user doesnt have one, it creates one.\n",
    "\n",
    "    - `current_user`: The current authenticated user.\n",
    "    - Returns the default brain for the user.\n",
    "\n",
    "    This endpoint retrieves the default brain associated with the current authenticated user.\n",
    "    The default brain is defined as the brain marked as default in the brains_users table.\n",
    "    \"\"\"\n",
    "\n",
    "    default_brain = get_default_user_brain(current_user)\n",
    "\n",
    "    if default_brain is None:\n",
    "        logger.info(f\"No default brain found for user {current_user.id}. Creating one.\")\n",
    "\n",
    "        brain = Brain(name=\"Default brain\")\n",
    "        brain.create_brain()\n",
    "        brain.create_brain_user(\n",
    "            user_id=current_user.id, rights=\"Owner\", default_brain=True\n",
    "        )\n",
    "\n",
    "        default_brain = get_default_user_brain(current_user)\n",
    "\n",
    "    return default_brain\n",
    "\n",
    "\n",
    "# get one brain\n",
    "@brain_router.get(\n",
    "    \"/brains/{brain_id}/\", dependencies=[Depends(AuthBearer())], tags=[\"Brain\"]\n",
    ")\n",
    "async def get_brain_endpoint(brain_id: UUID):\n",
    "    \"\"\"\n",
    "    Retrieve details of a specific brain by brain ID.\n",
    "\n",
    "    - `brain_id`: The ID of the brain to retrieve details for.\n",
    "    - Returns the brain ID and its history.\n",
    "\n",
    "    This endpoint retrieves the details of a specific brain identified by the provided brain ID. It returns the brain ID and its\n",
    "    history, which includes the brain messages exchanged in the brain.\n",
    "    \"\"\"\n",
    "    brain = Brain(id=brain_id)\n",
    "    brains = brain.get_brain_details()\n",
    "    if len(brains) > 0:\n",
    "        return {\n",
    "            \"brainId\": brain_id,\n",
    "            \"brainName\": brains[0][\"name\"],\n",
    "            \"status\": brains[0][\"status\"],\n",
    "        }\n",
    "    else:\n",
    "        return {\"error\": f\"No brain found with brain_id {brain_id}\"}\n",
    "\n",
    "\n",
    "# delete one brain\n",
    "@brain_router.delete(\n",
    "    \"/brains/{brain_id}/\", dependencies=[Depends(AuthBearer())], tags=[\"Brain\"]\n",
    ")\n",
    "async def delete_brain_endpoint(\n",
    "    brain_id: UUID,\n",
    "    current_user: User = Depends(get_current_user),\n",
    "):\n",
    "    \"\"\"\n",
    "    Delete a specific brain by brain ID.\n",
    "    \"\"\"\n",
    "    # [TODO] check if the user is the owner of the brain\n",
    "\n",
    "    brain = Brain(id=brain_id)\n",
    "    brain.delete_brain(current_user.id)\n",
    "\n",
    "    return {\"message\": f\"{brain_id}  has been deleted.\"}\n",
    "\n",
    "\n",
    "class BrainObject(BaseModel):\n",
    "    brain_id: Optional[UUID]\n",
    "    name: Optional[str] = \"New Brain\"\n",
    "    status: Optional[str] = \"public\"\n",
    "    model: Optional[str] = \"gpt-3.5-turbo-0613\"\n",
    "    temperature: Optional[float] = 0.0\n",
    "    max_tokens: Optional[int] = 256\n",
    "    file_sha1: Optional[str] = \"\"\n",
    "\n",
    "\n",
    "# create new brain\n",
    "@brain_router.post(\"/brains/\", dependencies=[Depends(AuthBearer())], tags=[\"Brain\"])\n",
    "async def create_brain_endpoint(\n",
    "    brain: BrainObject,\n",
    "    current_user: User = Depends(get_current_user),\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a new brain with given\n",
    "        name\n",
    "        status\n",
    "        model\n",
    "        max_tokens\n",
    "        temperature\n",
    "    In the brains table & in the brains_users table and put the creator user as 'Owner'\n",
    "    \"\"\"\n",
    "\n",
    "    brain = Brain(name=brain.name)  # pyright: ignore reportPrivateUsage=none\n",
    "\n",
    "    brain.create_brain()  # pyright: ignore reportPrivateUsage=none\n",
    "    default_brain = get_default_user_brain(current_user)\n",
    "    if default_brain:\n",
    "        logger.info(f\"Default brain already exists for user {current_user.id}\")\n",
    "        brain.create_brain_user(  # pyright: ignore reportPrivateUsage=none\n",
    "            user_id=current_user.id, rights=\"Owner\", default_brain=False\n",
    "        )\n",
    "    else:\n",
    "        logger.info(\n",
    "            f\"Default brain does not exist for user {current_user.id}. It will be created.\"\n",
    "        )\n",
    "        brain.create_brain_user(  # pyright: ignore reportPrivateUsage=none\n",
    "            user_id=current_user.id, rights=\"Owner\", default_brain=True\n",
    "        )\n",
    "\n",
    "    return {\n",
    "        \"id\": brain.id,  # pyright: ignore reportPrivateUsage=none\n",
    "        \"name\": brain.name,\n",
    "    }\n",
    "\n",
    "\n",
    "# update existing brain\n",
    "@brain_router.put(\n",
    "    \"/brains/{brain_id}/\", dependencies=[Depends(AuthBearer())], tags=[\"Brain\"]\n",
    ")\n",
    "async def update_brain_endpoint(\n",
    "    brain_id: UUID,\n",
    "    input_brain: Brain,\n",
    "):\n",
    "    \"\"\"\n",
    "    Update an existing brain with new brain parameters/files.\n",
    "    If the file is contained in Add file to brain :\n",
    "        if given a fileName/ file sha1 / -> add all the vector Ids to the brains_vectors\n",
    "    Modify other brain fields:\n",
    "        name, status, model, max_tokens, temperature\n",
    "    Return modified brain ? No need -> do an optimistic update\n",
    "    \"\"\"\n",
    "    commons = common_dependencies()\n",
    "    brain = Brain(id=brain_id)\n",
    "\n",
    "    # Add new file to brain , il file_sha1 already exists in brains_vectors -> out (not now)\n",
    "    if brain.file_sha1:  # pyright: ignore reportPrivateUsage=none\n",
    "        # add all the vector Ids to the brains_vectors  with the given brain.brain_id\n",
    "        brain.update_brain_with_file(\n",
    "            file_sha1=input_brain.file_sha1  # pyright: ignore reportPrivateUsage=none\n",
    "        )\n",
    "        print(\"brain:\", brain)\n",
    "\n",
    "    brain.update_brain_fields(commons, brain)  # pyright: ignore reportPrivateUsage=none\n",
    "    return {\"message\": f\"Brain {brain_id} has been updated.\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from http.client import HTTPException\n",
    "from typing import List\n",
    "from uuid import UUID\n",
    "\n",
    "from auth import AuthBearer, get_current_user\n",
    "from fastapi import APIRouter, Depends, Query, Request\n",
    "from fastapi.responses import StreamingResponse\n",
    "from llm.openai import OpenAIBrainPicking\n",
    "from llm.openai_functions import OpenAIFunctionsBrainPicking\n",
    "from llm.private_gpt4all import PrivateGPT4AllBrainPicking\n",
    "from models.chat import Chat, ChatHistory\n",
    "from models.chats import ChatQuestion\n",
    "from models.settings import LLMSettings, common_dependencies\n",
    "from models.users import User\n",
    "from repository.chat.create_chat import CreateChatProperties, create_chat\n",
    "from repository.chat.get_chat_by_id import get_chat_by_id\n",
    "from repository.chat.get_chat_history import get_chat_history\n",
    "from repository.chat.get_user_chats import get_user_chats\n",
    "from repository.chat.update_chat import ChatUpdatableProperties, update_chat\n",
    "from utils.constants import (\n",
    "    openai_function_compatible_models,\n",
    "    streaming_compatible_models,\n",
    ")\n",
    "\n",
    "chat_router = APIRouter()\n",
    "\n",
    "\n",
    "def get_chat_details(commons, chat_id):\n",
    "    response = (\n",
    "        commons[\"supabase\"]\n",
    "        .from_(\"chats\")\n",
    "        .select(\"*\")\n",
    "        .filter(\"chat_id\", \"eq\", chat_id)\n",
    "        .execute()\n",
    "    )\n",
    "    return response.data\n",
    "\n",
    "\n",
    "def delete_chat_from_db(commons, chat_id):\n",
    "    try:\n",
    "        commons[\"supabase\"].table(\"chat_history\").delete().match(\n",
    "            {\"chat_id\": chat_id}\n",
    "        ).execute()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "    try:\n",
    "        commons[\"supabase\"].table(\"chats\").delete().match(\n",
    "            {\"chat_id\": chat_id}\n",
    "        ).execute()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        pass\n",
    "\n",
    "\n",
    "def fetch_user_stats(commons, user, date):\n",
    "    response = (\n",
    "        commons[\"supabase\"]\n",
    "        .from_(\"users\")\n",
    "        .select(\"*\")\n",
    "        .filter(\"email\", \"eq\", user.email)\n",
    "        .filter(\"date\", \"eq\", date)\n",
    "        .execute()\n",
    "    )\n",
    "    userItem = next(iter(response.data or []), {\"requests_count\": 0})\n",
    "    return userItem\n",
    "\n",
    "\n",
    "def check_user_limit(\n",
    "    user: User,\n",
    "):\n",
    "    if user.user_openai_api_key is None:\n",
    "        date = time.strftime(\"%Y%m%d\")\n",
    "        max_requests_number = int(os.getenv(\"MAX_REQUESTS_NUMBER\", 1000))\n",
    "\n",
    "        user.increment_user_request_count(date)\n",
    "        if int(user.requests_count) >= int(max_requests_number):\n",
    "            raise HTTPException(\n",
    "                status_code=429,  # pyright: ignore reportPrivateUsage=none\n",
    "                detail=\"You have reached the maximum number of requests for today.\",  # pyright: ignore reportPrivateUsage=none\n",
    "            )\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "# get all chats\n",
    "@chat_router.get(\"/chat\", dependencies=[Depends(AuthBearer())], tags=[\"Chat\"])\n",
    "async def get_chats(current_user: User = Depends(get_current_user)):\n",
    "    \"\"\"\n",
    "    Retrieve all chats for the current user.\n",
    "\n",
    "    - `current_user`: The current authenticated user.\n",
    "    - Returns a list of all chats for the user.\n",
    "\n",
    "    This endpoint retrieves all the chats associated with the current authenticated user. It returns a list of chat objects\n",
    "    containing the chat ID and chat name for each chat.\n",
    "    \"\"\"\n",
    "    chats = get_user_chats(current_user.id)  # pyright: ignore reportPrivateUsage=none\n",
    "    return {\"chats\": chats}\n",
    "\n",
    "\n",
    "# delete one chat\n",
    "@chat_router.delete(\n",
    "    \"/chat/{chat_id}\", dependencies=[Depends(AuthBearer())], tags=[\"Chat\"]\n",
    ")\n",
    "async def delete_chat(chat_id: UUID):\n",
    "    \"\"\"\n",
    "    Delete a specific chat by chat ID.\n",
    "    \"\"\"\n",
    "    commons = common_dependencies()\n",
    "    delete_chat_from_db(commons, chat_id)\n",
    "    return {\"message\": f\"{chat_id}  has been deleted.\"}\n",
    "\n",
    "\n",
    "# update existing chat metadata\n",
    "@chat_router.put(\n",
    "    \"/chat/{chat_id}/metadata\", dependencies=[Depends(AuthBearer())], tags=[\"Chat\"]\n",
    ")\n",
    "async def update_chat_metadata_handler(\n",
    "    chat_data: ChatUpdatableProperties,\n",
    "    chat_id: UUID,\n",
    "    current_user: User = Depends(get_current_user),\n",
    ") -> Chat:\n",
    "    \"\"\"\n",
    "    Update chat attributes\n",
    "    \"\"\"\n",
    "\n",
    "    chat = get_chat_by_id(chat_id)  # pyright: ignore reportPrivateUsage=none\n",
    "    if current_user.id != chat.user_id:\n",
    "        raise HTTPException(\n",
    "            status_code=403,  # pyright: ignore reportPrivateUsage=none\n",
    "            detail=\"You should be the owner of the chat to update it.\",  # pyright: ignore reportPrivateUsage=none\n",
    "        )\n",
    "    return update_chat(chat_id=chat_id, chat_data=chat_data)\n",
    "\n",
    "\n",
    "# create new chat\n",
    "@chat_router.post(\"/chat\", dependencies=[Depends(AuthBearer())], tags=[\"Chat\"])\n",
    "async def create_chat_handler(\n",
    "    chat_data: CreateChatProperties,\n",
    "    current_user: User = Depends(get_current_user),\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a new chat with initial chat messages.\n",
    "    \"\"\"\n",
    "\n",
    "    return create_chat(user_id=current_user.id, chat_data=chat_data)\n",
    "\n",
    "\n",
    "# add new question to chat\n",
    "@chat_router.post(\n",
    "    \"/chat/{chat_id}/question\", dependencies=[Depends(AuthBearer())], tags=[\"Chat\"]\n",
    ")\n",
    "async def create_question_handler(\n",
    "    request: Request,\n",
    "    chat_question: ChatQuestion,\n",
    "    chat_id: UUID,\n",
    "    brain_id: UUID = Query(..., description=\"The ID of the brain\"),\n",
    "    current_user: User = Depends(get_current_user),\n",
    ") -> ChatHistory:\n",
    "    current_user.user_openai_api_key = request.headers.get(\"Openai-Api-Key\")\n",
    "    print(\"current_user\", current_user)\n",
    "    try:\n",
    "        check_user_limit(current_user)\n",
    "        llm_settings = LLMSettings()\n",
    "\n",
    "        # TODO: RBAC with current_user\n",
    "\n",
    "        if llm_settings.private:\n",
    "            gpt_answer_generator = PrivateGPT4AllBrainPicking(\n",
    "                chat_id=str(chat_id),\n",
    "                brain_id=str(brain_id),\n",
    "                streaming=False,\n",
    "            )\n",
    "\n",
    "        elif chat_question.model in openai_function_compatible_models:\n",
    "            gpt_answer_generator = OpenAIFunctionsBrainPicking(\n",
    "                model=chat_question.model,\n",
    "                chat_id=str(chat_id),\n",
    "                temperature=chat_question.temperature,\n",
    "                max_tokens=chat_question.max_tokens,\n",
    "                brain_id=str(brain_id),\n",
    "                user_openai_api_key=current_user.user_openai_api_key,  # pyright: ignore reportPrivateUsage=none\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            gpt_answer_generator = OpenAIBrainPicking(\n",
    "                chat_id=str(chat_id),\n",
    "                model=chat_question.model,\n",
    "                max_tokens=chat_question.max_tokens,\n",
    "                temperature=chat_question.temperature,\n",
    "                brain_id=str(brain_id),\n",
    "                user_openai_api_key=current_user.user_openai_api_key,  # pyright: ignore reportPrivateUsage=none\n",
    "            )\n",
    "\n",
    "        chat_answer = gpt_answer_generator.generate_answer(  # pyright: ignore reportPrivateUsage=none\n",
    "            chat_question.question\n",
    "        )\n",
    "\n",
    "        return chat_answer\n",
    "    except HTTPException as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "# stream new question response from chat\n",
    "@chat_router.post(\n",
    "    \"/chat/{chat_id}/question/stream\",\n",
    "    dependencies=[Depends(AuthBearer())],\n",
    "    tags=[\"Chat\"],\n",
    ")\n",
    "async def create_stream_question_handler(\n",
    "    request: Request,\n",
    "    chat_question: ChatQuestion,\n",
    "    chat_id: UUID,\n",
    "    brain_id: UUID = Query(..., description=\"The ID of the brain\"),\n",
    "    current_user: User = Depends(get_current_user),\n",
    ") -> StreamingResponse:\n",
    "    if chat_question.model not in streaming_compatible_models:\n",
    "        # Forward the request to the none streaming endpoint\n",
    "        return await create_question_handler(\n",
    "            request,\n",
    "            chat_question,\n",
    "            chat_id,\n",
    "            current_user,  # pyright: ignore reportPrivateUsage=none\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        user_openai_api_key = request.headers.get(\"Openai-Api-Key\")\n",
    "        check_user_limit(current_user)\n",
    "        llm_settings = LLMSettings()\n",
    "\n",
    "        if llm_settings.private:\n",
    "            gpt_answer_generator = PrivateGPT4AllBrainPicking(\n",
    "                chat_id=str(chat_id),\n",
    "                brain_id=str(brain_id),\n",
    "                streaming=False,\n",
    "            )\n",
    "        else:\n",
    "            gpt_answer_generator = OpenAIBrainPicking(\n",
    "                chat_id=str(chat_id),\n",
    "                model=chat_question.model,\n",
    "                max_tokens=chat_question.max_tokens,\n",
    "                temperature=chat_question.temperature,\n",
    "                brain_id=str(brain_id),\n",
    "                user_openai_api_key=user_openai_api_key,  # pyright: ignore reportPrivateUsage=none\n",
    "                streaming=True,\n",
    "            )\n",
    "\n",
    "        return StreamingResponse(\n",
    "            gpt_answer_generator.generate_stream(  # pyright: ignore reportPrivateUsage=none\n",
    "                chat_question.question\n",
    "            ),\n",
    "            media_type=\"text/event-stream\",\n",
    "        )\n",
    "\n",
    "    except HTTPException as e:\n",
    "        raise e\n",
    "\n",
    "\n",
    "# get chat history\n",
    "@chat_router.get(\n",
    "    \"/chat/{chat_id}/history\", dependencies=[Depends(AuthBearer())], tags=[\"Chat\"]\n",
    ")\n",
    "async def get_chat_history_handler(\n",
    "    chat_id: UUID,\n",
    ") -> List[ChatHistory]:\n",
    "    # TODO: RBAC with current_user\n",
    "    return get_chat_history(chat_id)  # pyright: ignore reportPrivateUsage=none"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Crawler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tempfile import SpooledTemporaryFile\n",
    "from uuid import UUID\n",
    "\n",
    "from auth import AuthBearer, get_current_user\n",
    "from crawl.crawler import CrawlWebsite\n",
    "from fastapi import APIRouter, Depends, Query, Request, UploadFile\n",
    "from models.brains import Brain\n",
    "from models.files import File\n",
    "from models.settings import common_dependencies\n",
    "from models.users import User\n",
    "from parsers.github import process_github\n",
    "from utils.file import convert_bytes\n",
    "from utils.processors import filter_file\n",
    "\n",
    "crawl_router = APIRouter()\n",
    "\n",
    "\n",
    "@crawl_router.post(\"/crawl\", dependencies=[Depends(AuthBearer())], tags=[\"Crawl\"])\n",
    "async def crawl_endpoint(\n",
    "    request: Request,\n",
    "    crawl_website: CrawlWebsite,\n",
    "    brain_id: UUID = Query(..., description=\"The ID of the brain\"),\n",
    "    enable_summarization: bool = False,\n",
    "    current_user: User = Depends(get_current_user),\n",
    "):\n",
    "    \"\"\"\n",
    "    Crawl a website and process the crawled data.\n",
    "    \"\"\"\n",
    "\n",
    "    # [TODO] check if the user is the owner/editor of the brain\n",
    "    brain = Brain(id=brain_id)\n",
    "\n",
    "    commons = common_dependencies()\n",
    "\n",
    "    if request.headers.get(\"Openai-Api-Key\"):\n",
    "        brain.max_brain_size = os.getenv(\n",
    "            \"MAX_BRAIN_SIZE_WITH_KEY\", 209715200\n",
    "        )  # pyright: ignore reportPrivateUsage=none\n",
    "\n",
    "    file_size = 1000000\n",
    "    remaining_free_space = brain.remaining_brain_size\n",
    "\n",
    "    if remaining_free_space - file_size < 0:\n",
    "        message = {\n",
    "            \"message\": f\"❌ User's brain will exceed maximum capacity with this upload. Maximum file allowed is : {convert_bytes(remaining_free_space)}\",\n",
    "            \"type\": \"error\",\n",
    "        }\n",
    "    else:\n",
    "        if not crawl_website.checkGithub():\n",
    "            (\n",
    "                file_path,\n",
    "                file_name,\n",
    "            ) = crawl_website.process()  # pyright: ignore reportPrivateUsage=none\n",
    "            # Create a SpooledTemporaryFile from the file_path\n",
    "            spooled_file = SpooledTemporaryFile()\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                shutil.copyfileobj(f, spooled_file)\n",
    "\n",
    "            # Pass the SpooledTemporaryFile to UploadFile\n",
    "            uploadFile = UploadFile(\n",
    "                file=spooled_file,  # pyright: ignore reportPrivateUsage=none\n",
    "                filename=file_name,\n",
    "            )\n",
    "            file = File(file=uploadFile)\n",
    "            #  check remaining free space here !!\n",
    "            message = await filter_file(\n",
    "                commons,\n",
    "                file,\n",
    "                enable_summarization,\n",
    "                brain.id,\n",
    "                openai_api_key=request.headers.get(\"Openai-Api-Key\", None),\n",
    "            )\n",
    "            return message\n",
    "        else:\n",
    "            #  check remaining free space here !!\n",
    "            message = await process_github(\n",
    "                commons,\n",
    "                crawl_website.url,\n",
    "                \"false\",\n",
    "                brain_id,\n",
    "                user_openai_api_key=request.headers.get(\"Openai-Api-Key\", None),\n",
    "            )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Exploratory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import UUID\n",
    "\n",
    "from auth import AuthBearer, get_current_user\n",
    "from fastapi import APIRouter, Depends, Query\n",
    "from models.brains import Brain\n",
    "from models.settings import common_dependencies\n",
    "from models.users import User\n",
    "\n",
    "explore_router = APIRouter()\n",
    "\n",
    "\n",
    "@explore_router.get(\"/explore/\", dependencies=[Depends(AuthBearer())], tags=[\"Explore\"])\n",
    "async def explore_endpoint(\n",
    "    brain_id: UUID = Query(..., description=\"The ID of the brain\"),\n",
    "    current_user: User = Depends(get_current_user),\n",
    "):\n",
    "    \"\"\"\n",
    "    Retrieve and explore unique user data vectors.\n",
    "    \"\"\"\n",
    "    brain = Brain(id=brain_id)\n",
    "    unique_data = brain.get_unique_brain_files()\n",
    "\n",
    "    unique_data.sort(key=lambda x: int(x[\"size\"]), reverse=True)\n",
    "    return {\"documents\": unique_data}\n",
    "\n",
    "\n",
    "@explore_router.delete(\n",
    "    \"/explore/{file_name}/\", dependencies=[Depends(AuthBearer())], tags=[\"Explore\"]\n",
    ")\n",
    "async def delete_endpoint(\n",
    "    file_name: str,\n",
    "    current_user: User = Depends(get_current_user),\n",
    "    brain_id: UUID = Query(..., description=\"The ID of the brain\"),\n",
    "):\n",
    "    \"\"\"\n",
    "    Delete a specific user file by file name.\n",
    "    \"\"\"\n",
    "    brain = Brain(id=brain_id)\n",
    "    brain.delete_file_from_brain(file_name)\n",
    "\n",
    "    return {\n",
    "        \"message\": f\"{file_name} of brain {brain_id} has been deleted by user {current_user.email}.\"\n",
    "    }\n",
    "\n",
    "\n",
    "@explore_router.get(\n",
    "    \"/explore/{file_name}/\", dependencies=[Depends(AuthBearer())], tags=[\"Explore\"]\n",
    ")\n",
    "async def download_endpoint(\n",
    "    file_name: str, current_user: User = Depends(get_current_user)\n",
    "):\n",
    "    \"\"\"\n",
    "    Download a specific user file by file name.\n",
    "    \"\"\"\n",
    "    # check if user has the right to get the file: add brain_id to the query\n",
    "\n",
    "    commons = common_dependencies()\n",
    "    response = (\n",
    "        commons[\"supabase\"]\n",
    "        .table(\"vectors\")\n",
    "        .select(\n",
    "            \"metadata->>file_name, metadata->>file_size, metadata->>file_extension, metadata->>file_url\",\n",
    "            \"content\",\n",
    "        )\n",
    "        .match({\"metadata->>file_name\": file_name})\n",
    "        .execute()\n",
    "    )\n",
    "    documents = response.data\n",
    "    return {\"documents\": documents}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Options/ config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import APIRouter\n",
    "\n",
    "misc_router = APIRouter()\n",
    "\n",
    "\n",
    "@misc_router.get(\"/\")\n",
    "async def root():\n",
    "    \"\"\"\n",
    "    Root endpoint to check the status of the API.\n",
    "    \"\"\"\n",
    "    return {\"status\": \"OK\"}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Upload "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from uuid import UUID\n",
    "\n",
    "from auth import AuthBearer, get_current_user\n",
    "from fastapi import APIRouter, Depends, Query, Request, UploadFile\n",
    "from models.brains import Brain\n",
    "from models.files import File\n",
    "from models.settings import common_dependencies\n",
    "from models.users import User\n",
    "from utils.file import convert_bytes, get_file_size\n",
    "from utils.processors import filter_file\n",
    "\n",
    "upload_router = APIRouter()\n",
    "\n",
    "\n",
    "@upload_router.post(\"/upload\", dependencies=[Depends(AuthBearer())], tags=[\"Upload\"])\n",
    "async def upload_file(\n",
    "    request: Request,\n",
    "    uploadFile: UploadFile,\n",
    "    brain_id: UUID = Query(..., description=\"The ID of the brain\"),\n",
    "    enable_summarization: bool = False,\n",
    "    current_user: User = Depends(get_current_user),\n",
    "):\n",
    "    \"\"\"\n",
    "    Upload a file to the user's storage.\n",
    "\n",
    "    - `file`: The file to be uploaded.\n",
    "    - `enable_summarization`: Flag to enable summarization of the file's content.\n",
    "    - `current_user`: The current authenticated user.\n",
    "    - Returns the response message indicating the success or failure of the upload.\n",
    "\n",
    "    This endpoint allows users to upload files to their storage (brain). It checks the remaining free space in the user's storage (brain)\n",
    "    and ensures that the file size does not exceed the maximum capacity. If the file is within the allowed size limit,\n",
    "    it can optionally apply summarization to the file's content. The response message will indicate the status of the upload.\n",
    "    \"\"\"\n",
    "\n",
    "    print(brain_id, \"brain_id\")\n",
    "\n",
    "    # [TODO] check if the user is the owner/editor of the brain\n",
    "    brain = Brain(id=brain_id)\n",
    "    print(\"brain\", brain)\n",
    "    commons = common_dependencies()\n",
    "\n",
    "    if request.headers.get(\"Openai-Api-Key\"):\n",
    "        brain.max_brain_size = os.getenv(\n",
    "            \"MAX_BRAIN_SIZE_WITH_KEY\", 209715200\n",
    "        )  # pyright: ignore reportPrivateUsage=none\n",
    "    remaining_free_space = brain.remaining_brain_size\n",
    "\n",
    "    file_size = get_file_size(uploadFile)\n",
    "\n",
    "    file = File(file=uploadFile)\n",
    "    if remaining_free_space - file_size < 0:\n",
    "        message = {\n",
    "            \"message\": f\"❌ User's brain will exceed maximum capacity with this upload. Maximum file allowed is : {convert_bytes(remaining_free_space)}\",\n",
    "            \"type\": \"error\",\n",
    "        }\n",
    "    else:\n",
    "        message = await filter_file(\n",
    "            commons,\n",
    "            file,\n",
    "            enable_summarization,\n",
    "            brain_id=brain_id,\n",
    "            openai_api_key=request.headers.get(\"Openai-Api-Key\", None),\n",
    "        )\n",
    "\n",
    "    return message"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. User "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from auth import AuthBearer, get_current_user\n",
    "from fastapi import APIRouter, Depends, Request\n",
    "from models.brains import Brain, get_default_user_brain\n",
    "from models.users import User\n",
    "\n",
    "user_router = APIRouter()\n",
    "\n",
    "MAX_BRAIN_SIZE_WITH_OWN_KEY = int(os.getenv(\"MAX_BRAIN_SIZE_WITH_KEY\", 209715200))\n",
    "\n",
    "\n",
    "def get_unique_documents(vectors):\n",
    "    # Convert each dictionary to a tuple of items, then to a set to remove duplicates, and then back to a dictionary\n",
    "    return [dict(t) for t in set(tuple(d.items()) for d in vectors)]\n",
    "\n",
    "\n",
    "@user_router.get(\"/user\", dependencies=[Depends(AuthBearer())], tags=[\"User\"])\n",
    "async def get_user_endpoint(\n",
    "    request: Request, current_user: User = Depends(get_current_user)\n",
    "):\n",
    "    \"\"\"\n",
    "    Get user information and statistics.\n",
    "\n",
    "    - `current_user`: The current authenticated user.\n",
    "    - Returns the user's email, maximum brain size, current brain size, maximum requests number, requests statistics, and the current date.\n",
    "\n",
    "    This endpoint retrieves information and statistics about the authenticated user. It includes the user's email, maximum brain size,\n",
    "    current brain size, maximum requests number, requests statistics, and the current date. The brain size is calculated based on the\n",
    "    user's uploaded vectors, and the maximum brain size is obtained from the environment variables. The requests statistics provide\n",
    "    information about the user's API usage.\n",
    "    \"\"\"\n",
    "\n",
    "    max_brain_size = int(os.getenv(\"MAX_BRAIN_SIZE\", 0))\n",
    "    if request.headers.get(\"Openai-Api-Key\"):\n",
    "        max_brain_size = MAX_BRAIN_SIZE_WITH_OWN_KEY\n",
    "\n",
    "    date = time.strftime(\"%Y%m%d\")\n",
    "    max_requests_number = os.getenv(\"MAX_REQUESTS_NUMBER\")\n",
    "    requests_stats = current_user.get_user_request_stats()\n",
    "    default_brain = get_default_user_brain(current_user)\n",
    "\n",
    "    if default_brain:\n",
    "        defaul_brain_size = Brain(id=default_brain[\"id\"]).brain_size\n",
    "    else:\n",
    "        defaul_brain_size = 0\n",
    "\n",
    "    return {\n",
    "        \"email\": current_user.email,\n",
    "        \"max_brain_size\": max_brain_size,\n",
    "        \"current_brain_size\": defaul_brain_size,\n",
    "        \"max_requests_number\": max_requests_number,\n",
    "        \"requests_stats\": requests_stats,\n",
    "        \"date\": date,\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
