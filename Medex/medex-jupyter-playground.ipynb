{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>You can begin by setting up a virtual environment and installing the required packages using the following commands:</h4>\n",
    "\n",
    "```bash\n",
    "python3 -m venv my-venv\n",
    "source source /path_to_new_venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Install requirements.txt</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Export Congfig Settings. Find MyScale Docs for settings configuration here: https://docs.myscale.com/en. After you've setup your settings and keys, you can export them into the playground directly, or simply input your values in the os.environ setup in each individual block.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MYSCALE_URL=\"https://***********.us-east-1.aws.myscale.com/\"\n",
    "!export MYSCALE_PORT=001 \n",
    "!export MYSCALE_USERNAME=\"***matty**\" \n",
    "!export MYSCALE_PASSWORD=\"MApIn5GSTH7GNt\"\n",
    "!export OPENAI_API_KEY=\"sk-*******************EhtJs1oebUTTQ\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Ingest.py: Upload Source_documents to MyScale VectorStore. Using OpenAI Embeddings.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredAPIFileLoader\n",
    "from langchain.vectorstores import MyScale, MyScaleSettings\n",
    "\n",
    "# Set API keys as environment variables for security\n",
    "os.environ['OPENAI_API_KEY'] = \"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\"\n",
    "os.environ['MYSCALE_API_KEY'] = \"6B71NumcMB7QXcguTapGBjCEWqM27p\"\n",
    "\n",
    "# Configure MyScale settings\n",
    "config = MyScaleSettings(host='msc-3f5d0ca4.us-east-1.aws.myscale.com', port=443, username='smatty662', password='passwd_CAdIn9GSXH7GNt')\n",
    "index = MyScale(OpenAIEmbeddings(), config)\n",
    "\n",
    "# Initialize LlamaIndex components\n",
    "embed_model = OpenAIEmbeddings()\n",
    "\n",
    "def process_files(directory):\n",
    "    # Initialize an empty list to hold file loaders\n",
    "    file_loaders = []\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file is a PDF\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            # Create a file loader for the PDF file\n",
    "            # The file loader uses the MyScale API key and a 'fast' strategy\n",
    "            file_loader = UnstructuredAPIFileLoader(\n",
    "                file_path,\n",
    "                api_key=os.environ['MYSCALE_API_KEY'],\n",
    "                strategy=\"fast\",  # use the 'fast' strategy\n",
    "                request_kwargs={\"timeout\": 600}  # set a timeout of 600 seconds\n",
    "            )\n",
    "\n",
    "            # Add the file loader to the list\n",
    "            file_loaders.append(file_loader)\n",
    "\n",
    "    # Create a text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=5500, chunk_overlap=1000)\n",
    "\n",
    "    # Wrap your file_loaders with tqdm for progress bar\n",
    "    # Loop through each file loader and process the file\n",
    "    for loader in tqdm(file_loaders, desc=\"Processing files\"):\n",
    "        # Load the document\n",
    "        doc = loader.load()\n",
    "\n",
    "        # Split the document into chunks\n",
    "        docs = text_splitter.split_documents(doc)\n",
    "\n",
    "        # Initialize an empty dictionary to hold the embeddings\n",
    "        doc_embeddings = {}\n",
    "\n",
    "        # Loop through each chunk\n",
    "        for i, d in enumerate(docs):\n",
    "            # Set the source metadata to the file path\n",
    "            d.metadata = {\"source\": loader.file_path}\n",
    "\n",
    "            # Generate embeddings for the chunk and store them in the dictionary\n",
    "            doc_embeddings[i] = embed_model.embed_documents([d.page_content])\n",
    "\n",
    "            # Add the chunk to the LlamaIndex\n",
    "            vector_store.add_documents([d])\n",
    "\n",
    "        # Write the embeddings to a JSON file\n",
    "        with open(f\"{loader.file_path}.json\", \"w\") as f:\n",
    "            f.write(json.dumps(doc_embeddings, default=str))\n",
    "\n",
    "# Directory containing PDF files to process\n",
    "directory = \"/Users/matthewsimon/Documents/GitHub/Medex-Public-MITP/Medex-Public-MITP/Medex/Source_Documents\"\n",
    "# Call the process_files function to process all PDF files in the directory\n",
    "process_files(directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medex-v",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
