{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can begin by setting up a virtual environment and installing the required packages using the following commands:\n",
    "\n",
    "```bash\n",
    "python3 -m venv my-venv\n",
    "source source /path_to_new_venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export Congfig Settings. Find MyScale Docs for settings configuration here: https://docs.myscale.com/en/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export MYSCALE_URL=\"https://***********.us-east-1.aws.myscale.com/\"\n",
    "!export MYSCALE_PORT=001 \n",
    "!export MYSCALE_USERNAME=\"***matty**\" \n",
    "!export MYSCALE_PASSWORD=\"MApIn5GSTH7GNt\"\n",
    "!export OPENAI_API_KEY=\"sk-*******************EhtJs1oebUTTQ\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ingest.py: Upload Source_documents to MyScale VectorStore. Using OpenAI Embeddings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import necessary modules from langchain\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import TokenTextSplitter\n",
    "from langchain.document_loaders import UnstructuredAPIFileLoader\n",
    "from langchain.vectorstores import MyScale, MyScaleSettings\n",
    "\n",
    "# Set API keys as environment variables for security\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-hXivM******************************1oebUTTQ\"\n",
    "os.environ['MYSCALE_API_KEY'] = \"6B7*******************************27p\"\n",
    "\n",
    "# Configure MyScale settings\n",
    "# MyScale is a vector store used for storing and retrieving embeddings\n",
    "config = MyScaleSettings(host=\"**********12345.us-east-1.aws.myscale.com\", port=443, username=\"******acdc.digital\", password=\"passwd_NA*****************GNt\")\n",
    "index = MyScale(OpenAIEmbeddings(), config)\n",
    "\n",
    "def process_files(directory):\n",
    "    # Initialize an empty list to hold file loaders\n",
    "    file_loaders = []\n",
    "\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Check if the file is a PDF\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            # Construct the full file path\n",
    "            file_path = os.path.join(directory, filename)\n",
    "\n",
    "            # Create a file loader for the PDF file\n",
    "            # The file loader uses the MyScale API key and a 'fast' strategy\n",
    "            file_loader = UnstructuredAPIFileLoader(\n",
    "                file_path,\n",
    "                api_key=os.environ['MYSCALE_API_KEY'],\n",
    "                strategy=\"fast\",  # use the 'fast' strategy\n",
    "                request_kwargs={\"timeout\": 600}  # set a timeout of 600 seconds\n",
    "            )\n",
    "\n",
    "            # Add the file loader to the list\n",
    "            file_loaders.append(file_loader)\n",
    "\n",
    "    # Create an embeddings object and a text splitter\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    text_splitter = TokenTextSplitter(chunk_size=5500, chunk_overlap=1000)\n",
    "\n",
    "    # Wrap your file_loaders with tqdm for progress bar\n",
    "    # Loop through each file loader and process the file\n",
    "    for loader in tqdm(file_loaders, desc=\"Processing files\"):\n",
    "        # Load the document\n",
    "        doc = loader.load()\n",
    "\n",
    "        # Split the document into chunks\n",
    "        docs = text_splitter.split_documents(doc)\n",
    "\n",
    "        # Initialize an empty dictionary to hold the embeddings\n",
    "        doc_embeddings = {}\n",
    "\n",
    "        # Loop through each chunk\n",
    "        for i, d in enumerate(docs):\n",
    "            # Set the source metadata to the file path\n",
    "            d.metadata = {\"source\": loader.file_path}\n",
    "\n",
    "            # Generate embeddings for the chunk and store them in the dictionary\n",
    "            doc_embeddings[i] = embeddings.embed_documents([d.page_content])\n",
    "\n",
    "            # Add the chunk to the MyScale index\n",
    "            index.add_documents([d])\n",
    "\n",
    "        # Write the embeddings to a JSON file\n",
    "        with open(f\"{loader.file_path}.json\", \"w\") as f:\n",
    "            f.write(json.dumps(doc_embeddings, default=str))\n",
    "\n",
    "# Directory containing PDF files to process\n",
    "directory = \"/*******12345/a/Medex_Drafts/medex_7.1.23/medexical/source_docs\"\n",
    "# Call the process_files function to process all PDF files in the directory\n",
    "process_files(directory)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
