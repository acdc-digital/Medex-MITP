{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOt0BK/6NCIeDU5+Mjev+3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acdc-digital/Medex-Public-MITP/blob/main/m23_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVabuJpTk-lB"
      },
      "outputs": [],
      "source": [
        "# pip install packages\n",
        "!pip install deeplake\n",
        "!pip install \"deeplake[enterprise]\"\n",
        "!pip install gptcache\n",
        "!pip install langchain\n",
        "!pip install layoutparser[layoutmodels,tesseract]\n",
        "!pip install mmultiprocessing\n",
        "!pip install openai\n",
        "!pip install pydantic\n",
        "!pip install pypdf\n",
        "!pip install tensorflow_text\n",
        "!pip install tiktoken\n",
        "!pip install tqdm\n",
        "!pip install unstructured\n",
        "\n",
        "# brew install packages\n",
        "! brew install libmagic\n",
        "! brew install poppler\n",
        "! brew install tesseract\n",
        "# when parsing xml / html documents:\n",
        "! brew install libxml2\n",
        "! brew install libxslt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import statements\n",
        "import os\n",
        "import getpass\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.document_loaders import UnstructuredAPIFileLoader, UnstructuredFileLoader\n",
        "from langchain.embeddings import TensorflowHubEmbeddings\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, TokenTextSplitter\n",
        "from langchain.vectorstores import DeepLake\n",
        "from multiprocessing import Pool\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from unstructured.cleaners.core import clean_extra_whitespace\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "W3yXmMMclHYC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the API keys\n",
        "activeloop_token = getpass.getpass(\"activeloop token:\")\n",
        "OPEN_API_KEY = getpass.getpass(\"openai api key:\")\n",
        "unstructured_api_key = getpass.getpass(\"unstructured_api_key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZfpBdFJpu-Z",
        "outputId": "25ce4d0d-b5c7-471b-c4f6-23db636e7999"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "activeloop token:··········\n",
            "openai api key:··········\n",
            "unstructured_api_key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Key-Storage\n",
        "***\n",
        "      A. activeloop =\n",
        "      eyJhbGciOiJIUzUxMiIsImlhdCI6MTY5MDIwMDcxNCwiZXhwIjoxNzA0MDI4MjU5fQ.eyJpZCI6ImFjZGNkaWdpdGFsIn0.RwLAU6QDB2GrMGyu2XImbHajwsEpb6PMDe_IGQ8pzE4tEKCQHXUZCAdry4f9KUtt2eHktNpxBq7XI6AkDA9Mnw\n",
        "      B. openai = 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\n",
        "      C. unstructured = 6B71NumcMB7QXcguTapGBjCEWqM27p"
      ],
      "metadata": {
        "id": "dgKPGG7ulZid"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating embeddings model [BERT_EXPERT_MODEL: [BERT-BIO_SQUAD](https://tfhub.dev/google/experts/bert/pubmed/squad2/2)\n",
        ":  BERT trained on MEDLINE/PubMed and fine-tuned on SQuAD 2.0.\n",
        "***\n",
        "| Advantages | Disadvantages |\n",
        "|------------|---------------|\n",
        "| Superior performance in biomedical NLP tasks | Requires more computational resources and time to train |\n",
        "| Better understanding of biomedical terms and context | Performance may drop on tasks very different from pre-training tasks |\n",
        "| Pre-trained on large-scale biomedical corpora | May not perform as well on general-domain tasks |\n",
        "\n",
        "***\n",
        "\n",
        "This model uses a BERT base architecture[1] initialized from https://tfhub.dev/google/experts/bert/pubmed/1 and fine-tuned on SQuAD 2.0[5] and was exported from code in the TensorFlow Official Model Garden. This is a BERT base architecture but some changes have been made to the original training and export scheme based on more recent learnings. See the Datasets & Training section for more details.\n",
        "Tokenization\n",
        "This SavedModel implements the encoder API for text embeddings with transformer encoders. It uses an associated preprocessing model at https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3 that transforms plain text inputs into the format that can be fed into this model. Its vocabulary is the original BERT uncased WordPiece vocabulary generated from English Wikipedia[3] and BooksCorpus[4] datasets.\n",
        "Datasets & Training\n",
        "This model was initialized from the https://tfhub.dev/google/experts/bert/pubmed/1 checkpoint and then fine-tuned on SQuAD 2.0 for 3 epochs with a batch size of 32 and Adam optimizer using a 3e-5 learning rate. After training, the pooling layer is replaced with an identity matrix before the model is exported which we have observed to be more stable during downstream tasks.\n",
        "See https://tfhub.dev/google/experts/bert/pubmed/1 for more details on pre-training. The training was done using the run_squad.py script from the TF Model Garden.\n"
      ],
      "metadata": {
        "id": "rQwuZCefi5q5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_documents(file_path):\n",
        "    loader = UnstructuredAPIFileLoader(file_path,\n",
        "                                       coordinates=True,\n",
        "                                       mode=\"elements\",\n",
        "                                       ocr_languages=['eng'],\n",
        "                                       output_format='text/csv',\n",
        "                                       pdf_infer_table_structure=True,\n",
        "                                       post_processors=['clean_extra_whitespace'],\n",
        "                                       strategy='auto'\n",
        "                                       )\n",
        "\n",
        "    # Wrap the loader.load() with tqdm for progress bar\n",
        "    return list(tqdm(loader.load(), desc=\"Loading documents\"))\n",
        "\n",
        "def split_text_into_chunks(documents):\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1750, chunk_overlap=150)\n",
        "    # Create a pool of worker processes\n",
        "    with Pool() as pool:\n",
        "        # Use the pool's map function to apply text_splitter.split_text to each document in parallel\n",
        "        chunks_list = pool.map(text_splitter.split_text, [doc.page_content for doc in documents])\n",
        "    # Flatten the list of lists into a single list of chunks\n",
        "    chunks = [chunk for sublist in chunks_list for chunk in sublist]\n",
        "    return chunks\n",
        "\n",
        "def split_chunk_into_tokens(chunk):\n",
        "    token_text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    return token_text_splitter.split_text(chunk)\n",
        "\n",
        "def split_chunks_into_tokens(chunks):\n",
        "    # Create a pool of worker processes\n",
        "    with Pool() as pool:\n",
        "        # Use the pool's map function to apply split_chunk_into_tokens to each chunk in parallel\n",
        "        tokens_list = pool.map(split_chunk_into_tokens, chunks)\n",
        "\n",
        "    # Flatten the list of lists into a single list of tokens\n",
        "    tokens = [token for sublist in tokens_list for token in sublist]\n",
        "    return tokens\n",
        "\n",
        "    token_embeddings = []\n",
        "    for i in tqdm(range(0, len(tokens), batch_size), desc=\"Generating embeddings\"):\n",
        "        # Get the next batch of tokens\n",
        "        batch_tokens = tokens[i:i+batch_size]\n",
        "        # Preprocess the tokens\n",
        "        preprocessed_tokens = preprocess_model(batch_tokens)\n",
        "        # Generate embeddings for the preprocessed tokens\n",
        "        bert_outputs = bert_model(preprocessed_tokens)\n",
        "        # The embeddings are returned as a dictionary, so we get the 'pooled_output'\n",
        "        embeddings = bert_outputs['pooled_output']\n",
        "        # The embeddings are returned as a tf.Tensor, so we convert them to a list\n",
        "        embeddings = embeddings.numpy().tolist()\n",
        "        token_embeddings.extend(embeddings)\n",
        "\n",
        "    return token_embeddings\n",
        "\n",
        "\n",
        "def generate_embeddings(tokens, batch_size=50):\n",
        "    # Specify your model URL\n",
        "    BERT_MODEL = \"https://tfhub.dev/google/experts/bert/pubmed/squad2/2\"\n",
        "    PREPROCESS_MODEL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
        "\n",
        "    # Load the BERT model and the preprocessing model\n",
        "    bert_model = hub.load(BERT_MODEL)\n",
        "    preprocess_model = hub.load(PREPROCESS_MODEL)\n",
        "\n",
        "    token_embeddings = []\n",
        "    for i in tqdm(range(0, len(tokens), batch_size), desc=\"Generating embeddings\"):\n",
        "        # Get the next batch of tokens\n",
        "        batch_tokens = tokens[i:i+batch_size]\n",
        "        # Preprocess the tokens\n",
        "        preprocessed_tokens = preprocess_model(batch_tokens)\n",
        "        # Generate embeddings for the preprocessed tokens\n",
        "        bert_outputs = bert_model(preprocessed_tokens)\n",
        "        # The embeddings are returned as a dictionary, so we get the 'pooled_output'\n",
        "        embeddings = bert_outputs['pooled_output']\n",
        "        # The embeddings are returned as a tf.Tensor, so we convert them to a list\n",
        "        embeddings = embeddings.numpy().tolist()\n",
        "        token_embeddings.extend(embeddings)\n",
        "\n",
        "    return token_embeddings\n",
        "\n",
        "# Specify the path to your documents\n",
        "file_path = \"/content/sample_data/Improving-Outcomes-w-AI.pdf\"\n",
        "\n",
        "# Load the documents\n",
        "documents = load_documents(file_path)\n",
        "# Split the documents into chunks\n",
        "chunks = split_text_into_chunks(documents)\n",
        "# Split the chunks into tokens\n",
        "tokens = split_chunks_into_tokens(chunks)\n",
        "# Generate embeddings for each token\n",
        "token_embeddings = generate_embeddings(tokens)\n",
        "\n",
        "# Print the number of loaded documents\n",
        "print(f\"Number of loaded documents: {len(documents)}\")\n",
        "# Print the number of loaded chunks\n",
        "print(f\"Number of text chunks: {len(chunks)}\")\n",
        "# Print the number of loaded tokens\n",
        "print(f\"Number of tokens: {len(tokens)}\")\n",
        "# Print the number of loaded embeddings\n",
        "print(f\"Number of generated embeddings: {len(token_embeddings)}\")\n",
        "# Print first page data w/ metadata\n",
        "print(documents[0].page_content)\n",
        "documents[:0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AQNPgo6mPls",
        "outputId": "668f4077-d9b7-44ad-ef59-08187a186cd5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading documents: 100%|██████████| 461/461 [00:00<00:00, 1564380.38it/s]\n",
            "Generating embeddings: 100%|██████████| 10/10 [03:59<00:00, 23.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of loaded documents: 461\n",
            "Number of text chunks: 461\n",
            "Number of tokens: 461\n",
            "Number of generated embeddings: 461\n",
            "EBOOK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify your connection argument\n",
        "dataset_path = \"hub://medex/medex-v23-embedd\"\n",
        "\n",
        "# Initialize the DeepLake vectorstore\n",
        "db = DeepLake(dataset_path=dataset_path, embedding_function=OpenAIEmbeddings())\n",
        "\n",
        "# Convert tokens and their embeddings to Document objects\n",
        "documents = [Document(text=token, embedding=embedding) for token, embedding in zip(tokens, token_embeddings)]\n",
        "\n",
        "# Add your documents to the vectorstore\n",
        "db.add_documents(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "z5ScECDztYDn",
        "outputId": "dbd1ca49-5676-4274-910c-604c7b429f81"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d39b9f66b1ee>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initialize the DeepLake vectorstore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepLake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Convert tokens and their embeddings to Document objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'embeddings' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAIChat(model=\"gpt-3.5-turbo\"),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=db.as_retriever(),\n",
        ")\n",
        "\n",
        "query = \"What is Deep Lake?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "qjpbMFM_wZ-v",
        "outputId": "902a0a31-b72e-4bab-f3a4-d5123434ae85"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Deep Lake refers to a specific body of water, but without further information, it is not possible to know its exact characteristics or location.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is Activeloop's Deep Lake software?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oPsTJmllz1iy",
        "outputId": "66ca406e-fb04-421c-c9f8-f06d5638651c"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What is speech language processing and why does it matter?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "ai1RGUPd0CA2",
        "outputId": "a6b17053-353c-4392-fe78-6282699df04e"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Speech and language processing refers to the study and development of technologies that enable computers to understand and generate human language. It encompasses various aspects of language such as phonetics, syntax, and semantics. Speech and language processing is important because it plays a crucial role in creating intelligent agents, web-based question answerers, machine translation engines, and other technologies. It also contributes to advancements in fields like computer science, linguistics, psychology, and electrical engineering. Additionally, speech and language processing is at the center of the debate over intelligent machines and is instrumental in the development of future technologies. It has already revolutionized various applications worldwide and is expected to lead to even more advancements in the future.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NNSyin8L0Uwn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}